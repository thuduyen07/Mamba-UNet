{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2023, Tri Dao.\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytest\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from mamba_ssm.ops.triton.selective_state_update import selective_state_update, selective_state_update_ref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"itype\", [torch.float32, torch.float16, torch.bfloat16])\n",
    "# @pytest.mark.parametrize('itype', [torch.float16])\n",
    "@pytest.mark.parametrize(\"has_z\", [False, True])\n",
    "# @pytest.mark.parametrize('has_z', [True])\n",
    "@pytest.mark.parametrize(\"dstate\", [16, 32, 64])\n",
    "# @pytest.mark.parametrize(\"dstate\", [16])\n",
    "@pytest.mark.parametrize(\"dim\", [2048, 2048 + 16, 4096])\n",
    "# @pytest.mark.parametrize(\"dim\", [2048])\n",
    "def test_causal_conv1d_update(dim, dstate, has_z, itype):\n",
    "    device = \"cuda\"\n",
    "    rtol, atol = (3e-4, 1e-3) if itype == torch.float32 else (5e-3, 1e-2)\n",
    "    if itype == torch.bfloat16:\n",
    "        rtol, atol = 1e-2, 5e-2\n",
    "    # set seed\n",
    "    torch.random.manual_seed(0)\n",
    "    batch_size = 2\n",
    "    state = torch.randn(batch_size, dim, dstate, dtype=itype, device=device)\n",
    "    x = torch.randn(batch_size, dim, device=device, dtype=itype)\n",
    "    dt = torch.randn(batch_size, dim, device=device, dtype=itype)\n",
    "    dt_bias = torch.rand(dim, device=device) - 4.0\n",
    "    A = -torch.rand(dim, dstate, device=device) - 1.0\n",
    "    B = torch.randn(batch_size, dstate, device=device)\n",
    "    C = torch.randn(batch_size, dstate, device=device)\n",
    "    D = torch.randn(dim, device=device)\n",
    "    if has_z:\n",
    "        z = torch.randn_like(x)\n",
    "    else:\n",
    "        z = None\n",
    "    state_ref = state.detach().clone()\n",
    "    out = selective_state_update(state, x, dt, A, B, C, D=D, z=z, dt_bias=dt_bias, dt_softplus=True)\n",
    "    out_ref = selective_state_update_ref(state_ref, x, dt, A, B, C, D=D, z=z, dt_bias=dt_bias, dt_softplus=True)\n",
    "\n",
    "    print(f\"Output max diff: {(out - out_ref).abs().max().item()}\")\n",
    "    print(f\"Output mean diff: {(out - out_ref).abs().mean().item()}\")\n",
    "    assert torch.allclose(state, state_ref, rtol=rtol, atol=atol)\n",
    "    assert torch.allclose(out, out_ref, rtol=rtol, atol=atol)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
